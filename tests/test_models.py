import pytest
import pandas as pd
import numpy as np
import scipy.stats as stats
from statsmodels.tsa.stattools import adfuller
import synthetica as sth

# Define the list of synthetic data simulators to be tested.
simulators = [
    sth.GeometricBrownianMotion,
    sth.Heston,
    sth.Merton,
    sth.Poisson,
    sth.LevyStable,
    sth.CIR,
    sth.MeanReverting,
    sth.AutoRegressive,
    sth.NARMA,
    sth.Seasonal
]


@pytest.fixture(params=simulators, ids=[sim.__name__ for sim in simulators])
def simulator_data(request: pytest.FixtureRequest):
    """
    Pytest fixture to generate synthetic data for each simulator.

    Parameters
    ----------
    request : _pytest.fixtures.FixtureRequest
        The request object that provides access to the parametrizing context.

    Yields
    ------
    tuple
        A tuple containing the simulator class and its generated data.
    """
    sim_class = request.param
    data = sim_class(3000, 10).transform()
    yield sim_class, data


def test_gbm(simulator_data: tuple):
    """
    Test for the Geometric Brownian Motion (GBM) simulator.

    This test checks if the log returns of the GBM data are normally 
    distributed.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing the GBM simulator class and its generated data.
    """
    sim_class, data = simulator_data
    if sim_class.__name__ != 'GeometricBrownianMotion':
        pytest.skip("Skipping non-GBM tests")

    log_returns = np.log(data / data.shift(1)).dropna()
    # Shapiro-Wilk test for normality
    _, pvalue = stats.shapiro(log_returns)
    # Assuming a significance level of 5%
    assert pvalue > 0.05, "Log returns not normally distributed"


def test_heston(simulator_data: tuple):
    """
    Test for the Heston model simulator.

    This test checks for volatility clustering in the data generated by the 
    Heston model.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing the Heston simulator class and its generated data.
    """
    sim_class, data = simulator_data
    if sim_class.__name__ != 'Heston':
        pytest.skip("Skipping non-Heston tests")

    # Calculate log returns and squared returns
    squared_returns = np.log(data / data.shift(1)).dropna()**2
    # Compute a measure of volatility (e.g., standard deviation of log returns)
    # Check for autocorrelation in volatility
    # Check for significant positive autocorrelation in squared returns
    assert any(
        squared_returns.apply(
            lambda col: any(
                col.autocorr(lag) > 0.1 for lag in range(1, 11)
            )
        )
    ), "Volatility clustering not detected"


def test_merton(simulator_data: tuple):
    """
    Test for the Merton model simulator.

    This test checks for the presence of jumps in asset prices as expected in 
    the Merton model.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing the Merton simulator class and its generated data.
    """
    sim_class, data = simulator_data
    if sim_class.__name__ != 'Merton':
        pytest.skip("Skipping non-Merton tests")

    # Calculate log returns
    # Identify outliers in the returns that could indicate jumps
    # Statistical tests for fat tails in the return distribution
    log_returns = np.log(data / data.shift(1)).dropna()
    z_scores = np.abs(stats.zscore(log_returns))
    # Check for values more than 3 standard deviations from the mean
    assert np.any(z_scores > 3), "Jumps not properly detected"


def test_poisson(simulator_data: tuple):
    """
    Test for the Poisson simulator.

    This test checks for noticeable jumps in the price path, which are 
    characteristic of a jump (poisson) process.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing the Jump Process simulator class and its generated 
        data.
    """
    sim_class, data = simulator_data
    if sim_class.__name__ != 'Poisson':
        pytest.skip("Skipping non-Poisson tests")
    # Calculate log returns
    # Analyze the frequency and magnitude of price changes
    # Compare these to expected jumps in a typical jump process
    log_returns = np.log(data / data.shift(1)).dropna()
    z_scores = np.abs(stats.zscore(log_returns))
    jump_count = np.sum(z_scores > 3)
    # Expect at least some jumps
    assert jump_count.sum() > 0, "Jump characteristics not as expected"
    expected_lambda = 2 * (1 / 252)
    assert sim_class().lambda_poisson == expected_lambda, \
        f"Expected lambda_poisson to be {expected_lambda}"


def test_mean_reverting(simulator_data: tuple):
    """
    Test for the Mean Reverting models, specifically the CIR and MeanReverting 
    simulators.

    This test uses the Augmented Dickey-Fuller test to check for mean reversion 
    in the data.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing either the CIR or MeanReverting simulator class and 
        its generated data.
    """
    sim_class, data = simulator_data
    if sim_class.__name__ not in ['CIR', 'MeanReverting']:
        pytest.skip("Skipping non-mean reverting tests")

    # Ornstein-Uhlenbeck process test for mean reversion
    # This could involve a statistical test like the Augmented Dickey-Fuller test
    # Check if data is a DataFrame, if not, convert it to DataFrame
    if not isinstance(data, pd.DataFrame):
        data = data.to_frame()

    # Perform the Augmented Dickey-Fuller test on each column
    p_values = [adfuller(data[col].dropna())[1] for col in data.columns]
    # Return True if all columns have p-value < 0.05 (indicating mean reversion)
    assert all(p < 0.05 for p in p_values), "No mean reversion detected"


# Common checks for all simulators
# Iterate over each simulator class
@pytest.mark.parametrize("length, num_paths", [
    (length, num_paths) for num_paths in range(10, 0, -1) for length in range(10, 100, 10)
])
def test_common_checks(simulator_data: tuple, length: int, num_paths: int):
    """
    Test common checks across all simulators.

    This test validates the output type and shape for different lengths and 
    numbers of paths.

    Parameters
    ----------
    simulator_data : tuple
        A tuple containing a simulator class and its generated data.
    length : int
        The length of the generated data.
    num_paths : int
        The number of paths in the generated data.
    """
    sim_class, _ = simulator_data
    # Test various lengths and number of paths for each simulator
    # Generate synthetic data using the current simulator
    data = sim_class(length, num_paths).transform()

    # Check if the output data is a pandas Series or DataFrame
    assert isinstance(data, (pd.Series, pd.DataFrame)), \
        "Not a pd.Series or pd.DataFrame."
    # Validate that the dimensions of the data match the specified length and
    # number of paths
    assert pd.DataFrame(data).shape == (length, num_paths), \
        "Shape does not match settings."
    # Additional tests could include checking the data type of elements in the
    # DataFrame or Series to ensure they are numerical values suitable for
    # synthetic data simulation
    # Example: Check if all elements in DataFrame or Series are numeric
    assert all(
        isinstance(value, (int, float, complex)
                   ) and not isinstance(value, bool)
        for value in pd.DataFrame(data).values.flatten()
    ), "Contains non-numeric values."



    # Generate random variables
    rvs = np.random.randn(100, 3)  # 100 samples, 3 variables
    
    
    # Test cholesky transform positive definite

    # Create a positive definite matrix
    A = np.array([[2, 0.5, 0.3], [0.5, 1, 0.4], [0.3, 0.4, 1]])
    # Perform the Cholesky transform
    transformed_rvs = sim_class.cholesky_transform(rvs, A)
    # Check the shape of the transformed variables
    assert transformed_rvs.shape == rvs.shape, \
        "Expected the shape of transformed variables to match the input"
    # Check that the transformed variables are not equal to the original ones
    assert not np.allclose(transformed_rvs, rvs), \
        "Expected transformed variables to differ from the original ones"

    
    # Test cholesky transform non positive definite

    # Create a non-positive definite matrix
    A = np.array([[1, 2, 3], [2, 1, 2], [3, 2, 1]])
    # Perform the Cholesky transform
    transformed_rvs = sim_class.cholesky_transform(rvs, A)

    # Check the shape of the transformed variables
    assert transformed_rvs.shape == rvs.shape, \
        "Expected the shape of transformed variables to match the input"

    # Check that the transformed variables are not equal to the original ones
    assert not np.allclose(transformed_rvs, rvs), \
        "Expected transformed variables to differ from the original ones"


    # Test cholesky transform identity matrix
    
    # Create an identity matrix
    A = np.eye(3)
    # Perform the Cholesky transform
    transformed_rvs = sim_class.cholesky_transform(rvs, A)
    # Check the shape of the transformed variables
    assert transformed_rvs.shape == rvs.shape, \
        "Expected the shape of transformed variables to match the input"
    # Check that the transformed variables are equal to the original ones
    assert np.allclose(transformed_rvs, rvs), \
        "Expected transformed variables to be the same as the original ones"

